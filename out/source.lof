\xpginauxfiletrue 
\addvspace {10\p@ }
\addvspace {10\p@ }
\setforeignlanguage {english}
\contentsline {figure}{\numberline {2.1}{\ignorespaces A visual explenation of residual learninig. Information flows through the shortcut connections as if they were identity mappings. The network learns the residual instead of a direct mapping. Residual neural networks use this property to achieve very large depth. }}{5}{}%
\addvspace {10\p@ }
\setforeignlanguage {english}
\contentsline {figure}{\numberline {3.1}{\ignorespaces ResNets can be considered as discretizations of an ODE solution. Under this assumption Resnet defines a continuous time vector field.}}{9}{}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\setforeignlanguage {english}
\contentsline {figure}{\numberline {5.1}{\ignorespaces Regression of the approximate solutions to the true solution. As the coefficients go to the optimum and the error function approaches the minimum the trajectories are getting closer to the true solution.}}{24}{}%
\setforeignlanguage {english}
\setforeignlanguage {english}
\setforeignlanguage {english}
\setforeignlanguage {english}
\contentsline {figure}{\numberline {5.2}{\ignorespaces The data are not linearly seperable}}{31}{}%
\setforeignlanguage {english}
\contentsline {figure}{\numberline {5.3}{\ignorespaces At convergence the vector field has learned to linearly seperate the datapoints}}{32}{}%
\setforeignlanguage {english}
\addvspace {10\p@ }
\setforeignlanguage {english}
\setforeignlanguage {english}
\addvspace {10\p@ }
\addvspace {10\p@ }
\setforeignlanguage {english}
\setforeignlanguage {english}
\setforeignlanguage {english}
\xpginauxfilefalse 
